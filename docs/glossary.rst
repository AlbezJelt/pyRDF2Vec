Glossary
========

.. glossary::

It's not always easy to understand all the notions used in ``pyRDF2Vec``. This
glossary is here to help you to have an idea behind all these notions:

Continuous Bag-of-Words (CBOW)
   Model part of ``Word2vec``, that predicts target words from contextual words
   in a given window.

depth
   Refers to the number of hops needed to reach sub-trees.

embedding technique
   Technique used in machine learning to represent complex objects (*e.g.,*
   texts, images, graphs) into a vector with a reduced number of features
   compared to the dimension of the dataset, while keeping the most important
   information about them.

embedding (or vector)
   Numerical representation of a word, regardless of where the words occurs in
   a sentence.

entities
   Sequences that allows unsupervised feature extraction using language
   modeling.

feature matrix
   2D vector created from a Knowledge Graph for downstream Machine
   Learning (ML) tasks.

Knowledge Graph (KG)
   Knowledge Base (KG) initiated by Google, which, through misuse of language,
   refers to the collection of domain-specific knowledge given in a form usable
   by a computer.

Knowledge Graph Embeddings (KGE)
   Contains a set of entities and relationships between these entities, where
   all the facts in a Knowledge Graph are represented as triples (subject,
   predicate, object).

object
   Noun or pronoun used in a sentence and which is acted upon by the subject.


predicate
   Often associated with a large part of a sentence, designating something from
   the subject concerned in that sentence.

RDF2Vec
   Creates vector representations of RDF graphs.

sample
   TODO

sampling strategy
   TODO

Skip-Gram (SG)
   Model part of ``Word2vec``, that predicts the context words from the target
   words in a given window.

SPARQL endpoint
   TODO

subject
   Noun or pronoun used in a sentence and related to an action.

transformer
   TODO

triple
   TODO

Uniform Resource Identifier (URI)
   Unique character string that identifies a particular resource, using a
   predefined set of syntax rules.

walk
   TODO

walker
   TODO

walking strategy
   TODO

Word2vec
   Neural language modeling techniques (NLP), which takes sequences of words to
   embed words into vector spaces.
